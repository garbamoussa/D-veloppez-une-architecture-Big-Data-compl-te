{"cells":[{"cell_type":"markdown","source":["# P8 - Déployer un modèle dans le cloud"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e75f4b39-326e-4acc-8c80-4243357838c4"}}},{"cell_type":"markdown","source":["# P8 - CLOUD - Microsoft Azure"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6760a63-a55f-49c7-bcf0-579684817504"}}},{"cell_type":"markdown","source":["Ce notebook traite de du chargement du jeu de données des images, du pré-processing, de la réduction de dimension et une classification pour des nouvelles images en utilisant **Microsoft Databricks Azure** et un **container blob de stockage** \"**Data Lake Storage**\"."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9d939a3-8180-4397-a9c8-f199b089b437"}}},{"cell_type":"markdown","source":["## 1. Introduction\n\n*****\n**Mission**\n*****\n**Développer dans un environnement Big Data une première chaîne de traitement des données qui comprendra le preprocessing et une étape de réduction de dimension** pour une startup Fruits! de l'AgriTech pour mettre à disposition du grand public une application mobile qui permettrait aux utilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n\n*****\n**Contraintes**\n*****\n- Le volume de données va augmenter très rapidement après la livraison de ce projet.\n- Développer des scripts en Pyspark.\n- Utiliser le cloud AWS ou autre (Microsoft Azure sera utilisé pour ce projet) pour profiter d’une architecture Big Data. \n\n*****\n**Sources**\n*****\n- [Jeu de données](https://www.kaggle.com/moltean/fruits) : constitué des images de fruits et des labels associés, qui pourra servir de point de départ pour construire une partie de la chaîne de traitement des données."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"798fc59a-0735-4ac6-809f-ef8f605d5875"}}},{"cell_type":"code","source":["%python\n# Chargement des librairies\nimport datetime\nimport io\nimport sys\nimport time\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\n\n# Visualisation\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Pyspark\nimport pyspark\nfrom pyspark.sql.functions import element_at, split, col, pandas_udf, PandasUDFType, udf\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql import SparkSession\n\n# Tensorflow Keras\nimport tensorflow as tf\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Gestion des images\nimport PIL\nfrom PIL import Image\n\n# Taches ML\nfrom pyspark.ml.image import ImageSchema\n\n# Réduction de dimension - PCA\nfrom pyspark.ml.feature import PCA\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n\n# Modélisation\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression, RandomForestClassifier, NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline\n\n# Matrice de confusion\nimport sklearn\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\n\n%matplotlib inline\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c940152-51f1-4dbc-95f8-d35af6665bdf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 2. Préparation des données du train set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32250e3d-9e68-4db0-8f49-729cc0348614"}}},{"cell_type":"markdown","source":["### 2.1. Jeu de données train set - au format \"binaryFile\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a09b15e-b5a9-44d6-89b4-e6a1d84a7921"}}},{"cell_type":"markdown","source":["#### 2.2.1. Connection du container blob de stockage à Azure Databricks"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0671ba49-ae91-4cd4-9bce-4a64d6873045"}}},{"cell_type":"code","source":["%python\ndbutils.fs.unmount(\"/mnt/p8-cloud\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84f07e93-f454-4fcc-9e80-8653c4e09e6d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndbutils.fs.mount(\n  source = \"wasbs://p8-cloud@p8cloud.blob.core.windows.net\",\n  mount_point = \"/mnt/p8-cloud\",\n  extra_configs = {\"fs.azure.account.key.p8cloud.blob.core.windows.net\":\"eO/iSSs9527scMebXetNiaApnpamHEq0G95gUYs3cBIjU3F4ZCUyx9xtzk9b05Aa8gqtL7kVXS94lTcWBFyBEQ==\"})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1653685-8a4e-4cac-b67f-424d2ad0ff3e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2.2.2. Chargement du jeu de données train set -\"binaryFile\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dad5261b-2ad4-46c0-ba80-1995ef295601"}}},{"cell_type":"code","source":["%python\npath_train_set = \"/mnt/p8-cloud/resources/data/train-set/*/*\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8329df9-f1e9-45a8-ba51-cffd9744fb99"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndf_binary_train = spark.read.format(\"binaryFile\") \\\n  .option(\"pathGlobFilter\", \"*.jpg\") \\\n  .option(\"recursiveFileLookup\", \"true\") \\\n  .load(path_train_set)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eca32c3a-f34d-4678-af2e-57c689a1dde3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndf_binary_train.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cab125b-76a0-479e-99db-f1aaef95d1a4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndf_binary_train.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc15cf36-888c-49ac-93fb-2f72a4c73664"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndf_binary_train.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c1cb026-a6a9-4db7-9f00-95ed2487fa2b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2.2.2. Création de la classe des images"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afe82a1b-05da-4ae0-8b1e-a5ed331be355"}}},{"cell_type":"code","source":["%python\n# Ajout dans la colonne Classe pour chaque image traitée de l'avant dernier\ndf_binary_train = df_binary_train.withColumn(\"Classe\", element_at(split(df_binary_train[\"path\"], \"/\"), -2))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71095bf7-5dc8-4e4d-abd2-c2e5f004f820"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Schéma ?\ndf_binary_train.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ac5b46e-1938-444e-b12d-b91d077f6a2f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 3. Extraction des features importantes pour chaque image"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7a73e09-5c9c-44d7-bf68-979bd8b8d22d"}}},{"cell_type":"markdown","source":["- Extraire les features les plus importantes pour la classification de nos images en utilisant un modèle **[InceptionV3](https://www.researchgate.net/figure/Schematic-diagram-of-the-Inception-v3-model-based-on-convolutional-neural-networks_fig3_337200783)** de deep learning pré-entrainé sur de la classification d'images."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47d5b1f3-650b-45b8-95ec-e544ed4b0cef"}}},{"cell_type":"markdown","source":["### 3.1. Préparation du dataframe de travail"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9666e500-3347-4dd1-a039-c08be0ffe163"}}},{"cell_type":"code","source":["%python\ndf_images = df_binary_train.select(\"path\", \"Classe\")\ndf_images.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cce3839-a293-4729-b343-63c737b515df"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3.2. Préparation du modèle InceptionV3"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a180f27b-d54b-46f1-ba3e-41a8a3cee799"}}},{"cell_type":"code","source":["%python\n# Instanciation du modèle\nmodel = InceptionV3(\n        include_top=False,  # Couche softmax de classification supprimée\n        weights='imagenet',  # Poids pré-entraînés sur Imagenet\n        input_shape=(100,100,3), # Image de taille 100x100 en couleur (channel=3)\n        pooling='max' # Utilisation du max de pooling\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae269120-75c2-487a-a1f1-2750dba01a92"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Description des caractéristiques du modèle\nmodel.summary()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d13e9cba-405f-49f5-afb1-83891315f46b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3.3. Extraction des features pour chaque image"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e28f90f-5d3e-4a92-b157-76f720adc119"}}},{"cell_type":"code","source":["%python\n# Instanciation du modèle\nmodel = InceptionV3(\n        include_top=False,  # Couche softmax de classification supprimée\n        weights='imagenet',  # Poids pré-entraînés sur Imagenet\n        input_shape=(100,100,3), # Image de taille 100x100 en couleur (channel=3)\n        pooling='max' # Utilisation du max de pooling\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75ede6c5-e96a-4065-8747-6b70998d9c6f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Permettre aux workers Spark d'accéder aux poids utilisés par le modèle\nbc_model_weights = spark.sparkContext.broadcast(model.get_weights())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a964cc3b-bdec-4dfe-b159-188bf51a3890"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndef model_fn():\n  \"\"\"\n  Renvoie un modèle Inception3 avec la couche supérieure supprimée et les poids pré-entraînés sur imagenet diffusés.\n  \"\"\"\n  model = InceptionV3(\n        include_top=False,  # Couche softmax de classification supprimée\n        weights='imagenet',  # Poids pré-entraînés sur Imagenet\n#         input_shape=(100,100,3), # Image de taille 100x100 en couleur (channel=3)\n        pooling='max' # Utilisation du max de pooling\n  )\n  model.set_weights(bc_model_weights.value)\n  \n  return model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82afc3c5-98b6-42c7-827e-e0b5f08bd67c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Redimensionnement des images en 299x299\ndef preprocess(content):\n    \"\"\"\n    Prétraite les octets de l'image brute pour la prédiction.\n    param : content : objet image, obligatoire\n    return : image redimensionnée en Array\n    \"\"\"\n    # lecture + redimension (299x299) pour Xception\n    img = PIL.Image.open(io.BytesIO(content)).resize([299, 299])\n    # transforme l'image en Array     \n    arr = img_to_array(img)\n    return preprocess_input(arr)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3854d659-e231-4638-a70a-a5e93f511a70"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Extraction des features par le modèle dans un vecteur\ndef featurize_series(model, content_series):\n  \"\"\"\n  Featurise une pd.Series d'images brutes en utilisant le modèle d'entrée.\n  param : \n    model : modèle à utiliser pour l'extraction, obligatoire.\n    content_series : image redimensionnée (299, 299, 3) en Array\n  :return: les features importantes de l'image en pd.Series.\n  \"\"\"\n  input = np.stack(content_series.map(preprocess))\n  # Prédiction du modèle\n  preds = model.predict(input)\n  # Pour certaines couches, les caractéristiques de sortie seront des tenseurs multidimensionnels.\n  # Nous aplatissons les tenseurs de caractéristiques en vecteurs pour faciliter le stockage dans\n  # les DataFrames de Spark.\n  output = [p.flatten() for p in preds]\n  \n  return pd.Series(output)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"881dedf0-c823-4a34-b1ed-4c739c83c30f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\ndef featurize_udf(content_series_iter):\n  '''\n  Cette méthode est un Scalar Iterator pandas UDF enveloppant notre fonction de featurisation.\n  Le décorateur spécifie que cette méthode renvoie une colonne Spark DataFrame de type ArrayType(FloatType).\n  \n  :param content_series_iter : Cet argument est un itérateur sur des lots de données, où chaque lot est une série pandas de données d'image.\n  '''\n  # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n  # for multiple data batches.  This amortizes the overhead of loading big models.\n  model = model_fn()\n  for content_series in content_series_iter:\n    yield featurize_series(model, content_series)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b987baf4-b51c-4ee9-9f5c-0daa88413fb4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Les UDF de Pandas sur de grands enregistrements (par exemple, de très grandes images) peuvent rencontrer des erreurs de type Out Of Memory (OOM).\n# Si vous rencontrez de telles erreurs dans la cellule ci-dessous, essayez de réduire la taille du lot Arrow via `maxRecordsPerBatch`.\nspark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54a71866-5652-4111-804e-12c355595b7f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Nous pouvons maintenant exécuter la featurisation sur l'ensemble de notre DataFrame Spark.\n# REMARQUE : Cela peut prendre beaucoup de temps (environ 10 minutes) car il applique un grand modèle à l'ensemble des données.\nfeatures_df = df_binary_train.repartition(16).select(col(\"path\"), col('Classe'), featurize_udf(\"content\").alias(\"features\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cdef4f7-81b8-475b-a744-3471bb9bd825"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# 4484 images?\nfeatures_df.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4e55e60-0d9d-447b-ad7f-f722c2adad45"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3.4. Réduction de dimension"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3caae69b-6d2a-4ea2-921d-7bd864821f8a"}}},{"cell_type":"markdown","source":["**Préparation des données**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f461438e-6a2c-493f-b336-6a0412e267f4"}}},{"cell_type":"code","source":["%python\ndef preprocess_pca(dataframe):\n  '''\n     Préparation des données :\n     - transformation en vecteur dense\n     - standardisation\n     param : dataframe : dataframe d'images\n     return : dataframe avec features vecteur dense standardisé\n  '''\n  \n  # Préparation des données - conversion des données images en vecteur dense\n  transform_vecteur_dense = udf(lambda r: Vectors.dense(r), VectorUDT())\n  dataframe = dataframe.withColumn('features_vectors', transform_vecteur_dense('features'))\n  \n  # Standardisation obligatoire pour PCA\n  scaler_std = StandardScaler(inputCol=\"features_vectors\", outputCol=\"features_scaled\", withStd=True, withMean=True)\n  model_std = scaler_std.fit(dataframe)\n  # Mise à l'échelle\n  dataframe = model_std.transform(dataframe)\n  \n  return dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9bcdca3-50d1-4e26-9c05-6d07f0a211cc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Recherche du nombre de composante expliquant 95% de la variance**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6a83c7e-bf3b-445d-9f9b-ca6c184e61ea"}}},{"cell_type":"code","source":["%python\ndef recherche_nb_composante(dataframe, nb_comp=400):\n    '''\n       Recherche d nombre de composante expliquant 95% de la variance\n       param : dataframe : dataframe d'images\n       return : k nombre de composante expliquant 95% de la variance totale\n    '''\n    \n    pca = PCA(k = nb_comp,\n              inputCol=\"features_scaled\", \n              outputCol=\"features_pca\")\n \n    model_pca = pca.fit(dataframe)\n    variance = model_pca.explainedVariance\n \n    # visuel\n    plt.plot(np.arange(len(variance)) + 1, variance.cumsum(), c=\"red\", marker='o')\n    plt.xlabel(\"Nb composantes\")\n    plt.ylabel(\"% variance\")\n    plt.show(block=False)\n \n    def nb_comp ():\n      for i in range(500):\n          a = variance.cumsum()[i]\n          if a >= 0.95:\n              print(\"{} composantes principales expliquent au moins 95% de la variance totale\".format(i))\n              break\n      return i\n \n    k=nb_comp()\n  \n    return k\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13376e7b-f1c8-4489-a266-a6db5643f85b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Pré-processing (vecteur dense, standardisation)\ndf_pca = preprocess_pca(features_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ba0be95-74f1-4fed-9b08-7328770920e1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Nombre de composante expliquant 95% de la variance\nn_components = recherche_nb_composante(df_pca)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aaa2e019-61c0-40e9-a706-31b0050865ba"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# 325 composantes expliquent plus de 90% de la variance\nn_components = 325"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"baa5a289-b0e0-4567-9d06-3977b213779b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["####Réduction de dimension PCA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"533a8078-76ea-405b-af44-d4d470d30f83"}}},{"cell_type":"code","source":["%python\n# Entrainement de l'algorithme\npca = PCA(k=n_components, inputCol='features_scaled', outputCol='vectors_pca')\nmodel_pca = pca.fit(df_pca)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3a68551-b010-4e40-8c5e-a6ea34b51200"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Transformation des images sur les k premières composantes\ndf_reduit = model_pca.transform(df_pca)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7bd9ce8-10b5-4fa1-a194-5f01f1bac8c4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Visualisation du dataframe réduit\ndf_reduit.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f7797e8-42ff-4d34-846c-2f77d40a4b56"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["####Sauvegarde des données"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"61957a62-ddf7-4430-a293-d13318ca0427"}}},{"cell_type":"code","source":["%python\n# Sauvegarde des données\ndf_reduit.write.mode(\"overwrite\").parquet(\"/mnt/p8-cloud/resources/output/resultats_features_parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0503edb-33be-4f1c-896a-6fb2dc31dfc1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 4. Test de classification"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a42834d2-1ca5-4a4f-b1ea-d7d2361ddba5"}}},{"cell_type":"markdown","source":["### 4.1. Préparation des données"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4173850c-e064-4b6b-a415-8c99fd58cd52"}}},{"cell_type":"markdown","source":["**Seed**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97b96372-9ffe-481a-b9ae-dfe2e8cfba72"}}},{"cell_type":"code","source":["%python\n# Nombre aléatoire pour la reproductibilité des résultats\nseed = 21"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"097a9675-55af-4751-93fa-a0060a20a367"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Dataframe de travail**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c73d1960-68ee-43a7-83cd-03b03114986d"}}},{"cell_type":"code","source":["%python\n# Chargement du dataframe sauvegardé en parquet\nparquetFiles = \"/mnt/p8-cloud/resources/output/resultats_features_parquet/\"\n\ndf_reduit = spark.read.parquet(parquetFiles)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8a84514-7c72-42a4-9104-f37f93217e78"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Conservation de la classe de l'image et des vecteurs pca\ndata = df_reduit[[\"Classe\", \"vectors_pca\"]]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7393f5c-4ef2-4659-a3a9-cff3e2d283df"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndata.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c584291-1f9a-44f0-83a0-42b76c1f2362"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Encodage de la variable cible**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f01cef4d-ed83-48cc-aefa-028ed7e35882"}}},{"cell_type":"code","source":["%python\n# Encodage de la variable cible : la classe de l'image acceptable par le modèle\nindexer = StringIndexer(inputCol=\"Classe\", outputCol=\"Classe_index\")\n\n# Fit the indexer to learn Classe/index pairs\nindexerModel = indexer.fit(data)\n\n# Append a new column with the index\ndata = indexerModel.transform(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"415dcb48-318b-4bf7-9fe3-0abcb405fc3e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndisplay(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6422733-1e72-47cc-a7e5-65bdc2ee7e4f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Découpage du jeu du train set en jeux d'entraînement et de validation**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0550432-1cec-4137-a3e7-aa533488da5d"}}},{"cell_type":"code","source":["%python\n# data splitting\n(train_data, valid_data) = data.randomSplit([0.8, 0.2])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc40404f-4c61-457e-bd07-b13bfd11a9fe"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\nprint(\"Nbre élément train_data : \" + str(train_data.count()))\nprint(\"Nbre élément valid_data : \" + str(valid_data.count()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c72aff68-a602-42b9-946f-84c2ffe3a50d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndisplay(train_data.head(3))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2196277-fa14-49ad-8791-89f37f9ae5a1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 4.2. Modélisation Logistic Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0fc7565-c5a7-49c4-85f1-1ac1d2228246"}}},{"cell_type":"markdown","source":["***Modélisation Régression Logistique***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5766d19e-9a60-486a-b72b-83d9748317ee"}}},{"cell_type":"markdown","source":["[Source](https://spark.apache.org/docs/latest/ml-classification-regression.html#multinomial-logistic-regression)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7f528ec-7344-49bf-9f9a-c4e2510b5f6c"}}},{"cell_type":"markdown","source":["***Entraînement du modèle***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3428e8b6-c627-4650-ab8c-a30c3e52c2bf"}}},{"cell_type":"code","source":["%python\n# Instanciation du modèle.\nlr = LogisticRegression(labelCol=\"Classe_index\", featuresCol=\"vectors_pca\",\n                        maxIter=5)\n\n# Entraînement du modèle\nlr_model = lr.fit(train_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5953ff67-8373-4c6e-b79e-076e56e3f14f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["***Prédictions***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4683266-65d4-4439-a9c3-411bf1c3879e"}}},{"cell_type":"code","source":["%python\n# Make predictions.\nlr_predictions = lr_model.transform(valid_data)\n\n# Select example rows to display.\nlr_predictions.select(\"prediction\", \"Classe_index\").show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f331e76d-10e0-4028-a355-76108d1a2d6e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["***Évaluation du modèle***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76d50b58-f34c-4c50-81a3-c1544843be25"}}},{"cell_type":"code","source":["%python\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"Classe_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\nlr_accuracy = evaluator.evaluate(lr_predictions)\nprint(\"Test Error = %g\" % (1.0 - lr_accuracy))\nprint(\"Accuracy = %g \" % lr_accuracy)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cda25d4-95e4-4897-91b8-a60aac205bb2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["***Informations sur le modèle***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2de8e42-d6d5-4ba9-8f17-0e7686855bce"}}},{"cell_type":"code","source":["%python\n# Print the coefficients and intercept for multinomial logistic regression\nprint(\"Coefficients: \\n\" + str(lr_model.coefficientMatrix))\nprint(\"Intercept: \" + str(lr_model.interceptVector))\n\ntrainingSummary = lr_model.summary\n\n# Obtain the objective per iteration\nobjectiveHistory = trainingSummary.objectiveHistory\nprint(\"objectiveHistory:\")\nfor objective in objectiveHistory:\n    print(objective)\n\n# for multiclass, we can inspect metrics on a per-label basis\nprint(\"False positive rate by label:\")\nfor i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n    print(\"label %d: %s\" % (i, rate))\n\nprint(\"True positive rate by label:\")\nfor i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n    print(\"label %d: %s\" % (i, rate))\n\nprint(\"Precision by label:\")\nfor i, prec in enumerate(trainingSummary.precisionByLabel):\n    print(\"label %d: %s\" % (i, prec))\n\nprint(\"Recall by label:\")\nfor i, rec in enumerate(trainingSummary.recallByLabel):\n    print(\"label %d: %s\" % (i, rec))\n\nprint(\"F-measure by label:\")\nfor i, f in enumerate(trainingSummary.fMeasureByLabel()):\n    print(\"label %d: %s\" % (i, f))\n\naccuracy = trainingSummary.accuracy\nfalsePositiveRate = trainingSummary.weightedFalsePositiveRate\ntruePositiveRate = trainingSummary.weightedTruePositiveRate\nfMeasure = trainingSummary.weightedFMeasure()\nprecision = trainingSummary.weightedPrecision\nrecall = trainingSummary.weightedRecall\nprint(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"513b99a3-f886-46d8-b051-567ffa750f17"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 4.3. Modélisation Decision Tree Classifier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff0ac776-9942-4d0a-89d6-6ad8e0b1b490"}}},{"cell_type":"markdown","source":["***Modélisation Decision Tree Classifier***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06f9c550-55e9-4c91-a69e-3f164ce030d5"}}},{"cell_type":"markdown","source":["[Source](https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd8ccac0-107a-4625-bc68-42276d5fab6a"}}},{"cell_type":"markdown","source":["***Entraînement du modèle***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36f75afd-ab1c-409e-adf5-3d622938b0d5"}}},{"cell_type":"code","source":["%python\n# Instanciation du modèle.\ndtc = DecisionTreeClassifier(labelCol=\"Classe_index\", featuresCol=\"vectors_pca\",\n                             seed=seed)\n\n# Entraînement du modèle\ndtc_model = dtc.fit(train_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a089aea-d100-41bd-83cf-c0c2253b8db0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["***Prédictions***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cd7e22d-7be1-412e-82f8-9d3b40ca6906"}}},{"cell_type":"code","source":["%python\n# Make predictions.\ndtc_predictions = dtc_model.transform(valid_data)\n\n# Select example rows to display.\ndtc_predictions.select(\"prediction\", \"Classe_index\").show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c582059-fbf5-4bf7-a8d8-ebc671f49939"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["***Évaluation du modèle***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e80762c-eded-4c96-8192-8631aa3b8a4d"}}},{"cell_type":"code","source":["%python\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"Classe_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\ndtc_accuracy = evaluator.evaluate(dtc_predictions)\nprint(\"Test Error = %g\" % (1.0 - dtc_accuracy))\nprint(\"Accuracy = %g \" % dtc_accuracy)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8aea5369-73a2-408a-a359-d44f30bc08c2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["***Informations sur le modèle***"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a36e839f-df10-4b91-846a-338e8ce19c80"}}},{"cell_type":"code","source":["%python\nprint(dtc_model.toDebugString)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d7c6c57-182a-446c-b6df-f33a11439179"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"P8_notebook_CLOUD_MICROSOFT_AZURE","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1560339374761439}},"nbformat":4,"nbformat_minor":0}
